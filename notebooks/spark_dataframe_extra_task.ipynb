{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fe03136",
   "metadata": {},
   "source": [
    "# Spark DataFrame Extra Task (готовий розвʼязок)\n",
    "\n",
    "Вимоги ТЗ:\n",
    "- **тільки DataFrame API** (без SQL-рядків)\n",
    "- локальний Spark `master('local[3]')`\n",
    "- результат кожної задачі відтворюється в ноутбуці через `.show()`\n",
    "\n",
    "Дані очікуються в папці `data/` (можуть бути й у підпапках — ноутбук знайде файли).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466b18d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T18:49:39.088528Z",
     "start_time": "2026-01-19T18:49:38.996769Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "843cdcaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T18:49:44.111273Z",
     "start_time": "2026-01-19T18:49:40.955759Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/19 21:01:40 WARN Utils: Your hostname, MacBook-Pro-Sergii.local resolves to a loopback address: 127.0.0.1; using 192.168.0.33 instead (on interface en0)\n",
      "26/01/19 21:01:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/19 21:01:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "26/01/19 21:01:40 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark: 3.5.1\n"
     ]
    }
   ],
   "source": [
    "# Spark session (LOCAL)\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master(\"local[3]\")\n",
    "    .appName(\"spark-hw\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "print(\"Spark:\", spark.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "262b58be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T18:49:47.887631Z",
     "start_time": "2026-01-19T18:49:47.863086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/sergiibeshliaga/PycharmProjects/spark-base\n",
      "Repo: /Users/sergiibeshliaga/PycharmProjects/spark-base\n",
      "Data dir: /Users/sergiibeshliaga/PycharmProjects/spark-base/data exists: True\n"
     ]
    }
   ],
   "source": [
    "# Robust repo/data detection\n",
    "cwd = Path.cwd().resolve()\n",
    "repo_root = None\n",
    "for p in [cwd, *cwd.parents]:\n",
    "    if (p / \"data\").exists():\n",
    "        repo_root = p\n",
    "        break\n",
    "if repo_root is None:\n",
    "    repo_root = cwd\n",
    "\n",
    "REPO_ROOT = repo_root\n",
    "DATA_DIR = (REPO_ROOT / \"data\").resolve()\n",
    "\n",
    "print(\"CWD:\", cwd)\n",
    "print(\"Repo:\", REPO_ROOT)\n",
    "print(\"Data dir:\", DATA_DIR, \"exists:\", DATA_DIR.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "681d5887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_file(name: str, base: Path = None) -> Path | None:\n",
    "    \"\"\"Find file under base folder (recursive, case-insensitive).\"\"\"\n",
    "    if base is None:\n",
    "        base = DATA_DIR\n",
    "    base = Path(base)\n",
    "    if not base.exists():\n",
    "        return None\n",
    "\n",
    "    p = base / name\n",
    "    if p.exists():\n",
    "        return p\n",
    "\n",
    "    lower = name.lower()\n",
    "    for x in base.iterdir():\n",
    "        if x.name.lower() == lower:\n",
    "            return x\n",
    "\n",
    "    hits = list(base.rglob(name))\n",
    "    if hits:\n",
    "        return hits[0]\n",
    "\n",
    "    for x in base.rglob(\"*\"):\n",
    "        if x.is_file() and x.name.lower() == lower:\n",
    "            return x\n",
    "    return None\n",
    "\n",
    "def read_csv(name: str):\n",
    "    path = locate_file(name)\n",
    "    if path is None:\n",
    "        raise FileNotFoundError(f\"{name} not found under {DATA_DIR}\")\n",
    "    return spark.read.csv(str(path), header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3252b1",
   "metadata": {},
   "source": [
    "## Load tables (CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a29961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables loaded\n"
     ]
    }
   ],
   "source": [
    "actor_df = read_csv('actor.csv')\n",
    "address_df = read_csv('address.csv')\n",
    "category_df = read_csv('category.csv')\n",
    "city_df = read_csv('city.csv')\n",
    "country_df = read_csv('country.csv')\n",
    "customer_df = read_csv('customer.csv')\n",
    "film_df = read_csv('film.csv')\n",
    "film_actor_df = read_csv('film_actor.csv')\n",
    "film_category_df = read_csv('film_category.csv')\n",
    "inventory_df = read_csv('inventory.csv')\n",
    "language_df = read_csv('language.csv')\n",
    "payment_df = read_csv('payment.csv')\n",
    "rental_df = read_csv('rental.csv')\n",
    "staff_df = read_csv('staff.csv')\n",
    "store_df = read_csv('store.csv')\n",
    "\n",
    "print('Tables loaded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89130fb0",
   "metadata": {},
   "source": [
    "# Домашнє завдання на тему Spark SQL\n",
    "\n",
    "Задачі з домашнього завдання на SQL потрібно розвʼязати за допомогою Spark SQL DataFrame API.\n",
    "\n",
    "- Дампи таблиць знаходяться в папці `data`.\n",
    "- Розвʼязок кожної задачі має бути відображений в самому файлі (використати метод `.show()`).\n",
    "- Використовувати SQL-рядки заборонено — **тільки DataFrame API**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c645db5c",
   "metadata": {},
   "source": [
    "## 1. Вивести кількість фільмів в кожній категорії. Результат відсортувати за спаданням.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76543406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|name       |films_cnt|\n",
      "+-----------+---------+\n",
      "|Sports     |74       |\n",
      "|Foreign    |73       |\n",
      "|Family     |69       |\n",
      "|Documentary|68       |\n",
      "|Animation  |66       |\n",
      "|Action     |64       |\n",
      "|New        |63       |\n",
      "|Drama      |62       |\n",
      "|Games      |61       |\n",
      "|Sci-Fi     |61       |\n",
      "|Children   |60       |\n",
      "|Comedy     |58       |\n",
      "|Travel     |57       |\n",
      "|Classics   |57       |\n",
      "|Horror     |56       |\n",
      "|Music      |51       |\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task1 = (\n",
    "    film_category_df\n",
    "    .join(category_df, on='category_id', how='inner')\n",
    "    .groupBy('name')\n",
    "    .agg(F.countDistinct('film_id').alias('films_cnt'))\n",
    "    .orderBy(F.desc('films_cnt'))\n",
    ")\n",
    "task1.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c911a9c0",
   "metadata": {},
   "source": [
    "## 2. Вивести 10 акторів, чиї фільми брали на прокат найбільше. Результат відсортувати за спаданням.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48a90e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+-----------+\n",
      "|actor_id|first_name|last_name  |rentals_cnt|\n",
      "+--------+----------+-----------+-----------+\n",
      "|107     |GINA      |DEGENERES  |753        |\n",
      "|181     |MATTHEW   |CARREY     |678        |\n",
      "|198     |MARY      |KEITEL     |674        |\n",
      "|144     |ANGELA    |WITHERSPOON|654        |\n",
      "|102     |WALTER    |TORN       |640        |\n",
      "|60      |HENRY     |BERRY      |612        |\n",
      "|150     |JAYNE     |NOLTE      |611        |\n",
      "|37      |VAL       |BOLGER     |605        |\n",
      "|23      |SANDRA    |KILMER     |604        |\n",
      "|90      |SEAN      |GUINESS    |599        |\n",
      "+--------+----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task2 = (\n",
    "    rental_df\n",
    "    .join(inventory_df.select('inventory_id', 'film_id'), on='inventory_id', how='inner')\n",
    "    .join(film_actor_df, on='film_id', how='inner')\n",
    "    .join(actor_df, on='actor_id', how='inner')\n",
    "    .groupBy('actor_id', 'first_name', 'last_name')\n",
    "    .agg(F.count('*').alias('rentals_cnt'))\n",
    "    .orderBy(F.desc('rentals_cnt'))\n",
    "    .limit(10)\n",
    ")\n",
    "task2.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9d66be",
   "metadata": {},
   "source": [
    "## 3. Вивести категорію фільмів, на яку було витрачено найбільше грошей в прокаті\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8a94d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+\n",
      "|name  |total_amount     |\n",
      "+------+-----------------+\n",
      "|Sports|5314.209999999848|\n",
      "+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task3 = (\n",
    "    payment_df\n",
    "    .join(rental_df.select('rental_id', 'inventory_id'), on='rental_id', how='inner')\n",
    "    .join(inventory_df.select('inventory_id', 'film_id'), on='inventory_id', how='inner')\n",
    "    .join(film_category_df, on='film_id', how='inner')\n",
    "    .join(category_df, on='category_id', how='inner')\n",
    "    .groupBy('name')\n",
    "    .agg(F.sum('amount').alias('total_amount'))\n",
    "    .orderBy(F.desc('total_amount'))\n",
    "    .limit(1)\n",
    ")\n",
    "task3.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2715912",
   "metadata": {},
   "source": [
    "## 4. Вивести назви фільмів, яких не має в inventory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "913e44db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------+\n",
      "|film_id|title                 |\n",
      "+-------+----------------------+\n",
      "|14     |ALICE FANTASIA        |\n",
      "|33     |APOLLO TEEN           |\n",
      "|36     |ARGONAUTS TOWN        |\n",
      "|38     |ARK RIDGEMONT         |\n",
      "|41     |ARSENIC INDEPENDENCE  |\n",
      "|87     |BOONDOCK BALLROOM     |\n",
      "|108    |BUTCH PANTHER         |\n",
      "|128    |CATCH AMISTAD         |\n",
      "|144    |CHINATOWN GLADIATOR   |\n",
      "|148    |CHOCOLATE DUCK        |\n",
      "|171    |COMMANDMENTS EXPRESS  |\n",
      "|192    |CROSSING DIVORCE      |\n",
      "|195    |CROWDS TELEMARK       |\n",
      "|198    |CRYSTAL BREAKING      |\n",
      "|217    |DAZED PUNK            |\n",
      "|221    |DELIVERANCE MULHOLLAND|\n",
      "|318    |FIREHOUSE VIETNAM     |\n",
      "|325    |FLOATS GARDEN         |\n",
      "|332    |FRANKENSTEIN STRANGER |\n",
      "|359    |GLADIATOR WESTWARD    |\n",
      "+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task4 = (\n",
    "    film_df\n",
    "    .select('film_id', 'title')\n",
    "    .join(inventory_df.select('film_id').distinct(), on='film_id', how='left_anti')\n",
    "    .orderBy('title')\n",
    ")\n",
    "task4.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd8e29d",
   "metadata": {},
   "source": [
    "## 5. Вивести топ 3 актори, які найбільше зʼявлялись в категорії фільмів “Children”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09dab777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+-----------------+\n",
      "|actor_id|first_name|last_name|films_in_children|\n",
      "+--------+----------+---------+-----------------+\n",
      "|17      |HELEN     |VOIGHT   |7                |\n",
      "|127     |KEVIN     |GARLAND  |5                |\n",
      "|140     |WHOOPI    |HURT     |5                |\n",
      "+--------+----------+---------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "children_cat = category_df.filter(F.col('name') == F.lit('Children')).select('category_id')\n",
    "\n",
    "task5 = (\n",
    "    film_category_df\n",
    "    .join(children_cat, on='category_id', how='inner')\n",
    "    .join(film_actor_df, on='film_id', how='inner')\n",
    "    .join(actor_df, on='actor_id', how='inner')\n",
    "    .groupBy('actor_id', 'first_name', 'last_name')\n",
    "    .agg(F.countDistinct('film_id').alias('films_in_children'))\n",
    "    .orderBy(F.desc('films_in_children'))\n",
    "    .limit(3)\n",
    ")\n",
    "task5.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1336bbf3",
   "metadata": {},
   "source": [
    "## Stop Spark session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b8b18eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark stopped\n"
     ]
    }
   ],
   "source": [
    "spark.stop()\n",
    "print('Spark stopped')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
